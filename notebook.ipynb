{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Road Sign Recognition system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as path\n",
    "import skimage as skimg\n",
    "import matplotlib.pyplot as plt\n",
    "from functional import seq\n",
    "from random import sample, seed\n",
    "import numpy as np\n",
    "from rsr import Data\n",
    "from loguru import logger\n",
    "\n",
    "logger.remove()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Loading dataset\n",
    " Load the data from the `/cropped/` directory, convert the directory name to integer and used them as labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Dataset distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStat(dataset, groups):\n",
    "    for group in groups:\n",
    "        print(f'{Data.fromIndex(group[0])}: {len(group[1])}')\n",
    "    print(f'Total: {len(dataset)}')\n",
    "\n",
    "    plt.bar(seq(groups).select(lambda group: Data.fromIndex(group[0])).to_list(), seq(groups).select(lambda group: len(group[1])).to_list())\n",
    "    plt.show()\n",
    "\n",
    "printStat(dataset, groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Visualizing dataset\n",
    " Displaying 10 random samples for each label\n",
    "\n",
    " _Here, the random seed is set to 0_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(0)\n",
    "# todo: rename to show list of images\n",
    "def showDataset(dataset, title, cols = 10, figsize = (15, 15), y = 0.6):\n",
    "    rows = len(dataset) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    cmap = None\n",
    "    for axe, image in zip(axes.ravel(), seq(dataset).select(lambda data: data.image)):\n",
    "        axe.axis('off')\n",
    "        if len(image.shape)< 3 or image.shape[-1] < 3:\n",
    "            cmap = \"gray\"\n",
    "        axe.imshow(image, cmap = cmap)\n",
    "    \n",
    "    fig.suptitle(title, y=y)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def sampleDataset(dataset, count=10):\n",
    "    groups = groupDataset(dataset)\n",
    "    for group in groups:\n",
    "        showDataset(sample(group[1], count), Data.fromIndex(group[0]), cols=count)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDataset(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minMaxAverage(title, items):\n",
    "    print(f'Minimum {title}: {seq(items).min()}')\n",
    "    print(f'Maximum {title}: {seq(items).max()}')\n",
    "    print(f'Average {title}: {seq(items).average()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Average width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Average height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here, we only sample 100 images for testing out the preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set\n",
    "validationSet = sample(dataset, 100)\n",
    "showDataset(validationSet, \"Validation set\", 5, y = 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grayscale\n",
    "for data in validationSet:\n",
    "    data.grayscale()\n",
    "\n",
    "showDataset(validationSet, \"Grayscale\", 5, y = 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram equalization\n",
    "for data in validationSet:\n",
    "    data.equalize()\n",
    "\n",
    "showDataset(validationSet, \"Histogram equalization\", 5, y = 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize\n",
    "for data in validationSet:\n",
    "    data.resize()\n",
    "\n",
    "showDataset(validationSet, \"Resize\", 5, y = 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaxAverage(\"width\", seq(validationSet).select(lambda data: data.image.shape[0]))\n",
    "minMaxAverage(\"height\", seq(validationSet).select(lambda data: data.image.shape[1]))\n",
    "seq(validationSet).select(lambda data: data.image.shape)\n",
    "\n",
    "\n",
    "# data augmentation? \n",
    "\n",
    "# sampleDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def train(dataset):\n",
    "    data = np.array(seq(dataset).select(lambda data: data.image).to_list()).reshape(len(dataset), -1)\n",
    "    labels = np.array(seq(dataset).select(lambda data: data.label).to_list()).reshape(len(dataset), -1).reshape(-1)\n",
    "\n",
    "    trainingData, testingData, trainingLabels, testingLabels = train_test_split(data, labels, random_state=0)\n",
    "    print(f'trainingData: {trainingData.shape}, trainingLabels: {trainingLabels.shape}')\n",
    "    print(f'testingData: {testingData.shape}, testingLabels: {testingLabels.shape}')\n",
    "\n",
    "    minMaxAverage(\"training\", trainingData.ravel())\n",
    "    minMaxAverage(\"testing\", testingData.ravel())\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    trainingData = scaler.fit_transform(trainingData)\n",
    "    testingData = scaler.fit_transform(testingData)\n",
    "    print(\"---\")\n",
    "    minMaxAverage(\"training\", trainingData.ravel())\n",
    "    minMaxAverage(\"testing\", testingData.ravel())\n",
    "\n",
    "    mlp = MLPClassifier(random_state=0)\n",
    "    mlp.fit(trainingData, trainingLabels)\n",
    "    print(mlp)\n",
    "    print(f'training accuracy: {mlp.score(trainingData, trainingLabels)}')\n",
    "    print(f'testing accuracy: {mlp.score(testingData, testingLabels)}')\n",
    "\n",
    "    predictedLabels = mlp.predict(testingData)\n",
    "    print(f'confusion matrix: \\n {confusion_matrix(testingLabels, predictedLabels)}')\n",
    "\n",
    "    \n",
    "\n",
    "train(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
